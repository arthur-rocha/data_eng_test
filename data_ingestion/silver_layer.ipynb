{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "630f4c55-a6dc-44ab-875d-9c6c6e49c5cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Camada Silver\n",
    "\n",
    "- Aqui irei criar as tabelas fatos e dimensoes, tendo mais preocupacao com a ingestao e tipagem do dado em si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8904a1b2-72bd-4de4-836a-d2a9c47609fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimensoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd5258df-79f2-40af-932c-8e0219ae5337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, to_date, col\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    LongType,\n",
    "    DateType,\n",
    "    StringType,\n",
    "    FloatType,\n",
    "    IntegerType\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68b267f0-16a7-42a8-8c3f-9232c01de773",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dim brand"
    }
   },
   "outputs": [],
   "source": [
    "#schema\n",
    "schema_dim_brand = StructType([\n",
    "    StructField(\"CE_BRAND_FLVR\", StringType(), nullable=False),\n",
    "    StructField(\"BRAND_NM\", StringType(), True)\n",
    "])\n",
    "\n",
    "#agregando dado para criar dimensao\n",
    "dim_brand = spark.table(\"ab_inbev.bronze.beverage_sales\").select(\"CE_BRAND_FLVR\", \"BRAND_NM\").distinct()\n",
    "\n",
    "#forcando schema\n",
    "dim_brand = spark.createDataFrame(dim_brand.rdd, schema=schema_dim_brand)\n",
    "\n",
    "#escrita\n",
    "dim_brand.write.mode(\"overwrite\").saveAsTable(\"ab_inbev.silver.dim_brand\")\n",
    "\n",
    "#chave primaria\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.dim_brand ALTER COLUMN CE_BRAND_FLVR SET NOT NULL\") #gambiarra\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.dim_brand ADD PRIMARY KEY (CE_BRAND_FLVR)\")\n",
    "\n",
    "spark.table(\"ab_inbev.silver.dim_brand\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e5470b0-b08f-4272-8f80-c8dfc13afd84",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dim channel"
    }
   },
   "outputs": [],
   "source": [
    "#schema\n",
    "schema_dim_channels = StructType([\n",
    "    StructField(\"TRADE_CHNL_DESC\", StringType(), nullable=False),\n",
    "    StructField(\"TRADE_GROUP_DESC\", StringType(), True),\n",
    "    StructField(\"TRADE_TYPE_DESC\", StringType(), True)\n",
    "])\n",
    "\n",
    "#agregando dado para criar dimensao\n",
    "dim_channels = spark.table(\"ab_inbev.bronze.beverage_sales_and_channels\") \\\n",
    "    .select(\"TRADE_CHNL_DESC\", \"TRADE_GROUP_DESC\", \"TRADE_TYPE_DESC\") \\\n",
    "    .distinct()\n",
    "\n",
    "#forcando schema\n",
    "dim_channels = spark.createDataFrame(dim_channels.rdd, schema=schema_dim_channels)\n",
    "\n",
    "#escrita\n",
    "dim_channels.write.mode(\"overwrite\").saveAsTable(\"ab_inbev.silver.dim_channels\")\n",
    "\n",
    "#chave primaria\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.dim_channels ALTER COLUMN TRADE_CHNL_DESC SET NOT NULL\") #gambiarra\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.dim_channels ADD PRIMARY KEY (TRADE_CHNL_DESC)\")\n",
    "\n",
    "spark.table(\"ab_inbev.silver.dim_channels\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "863d3778-b621-406e-95e5-73840b0053ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(\"ab_inbev.bronze.beverage_sales\").select(\"PKG_CAT\", \"Pkg_Cat_Desc\", \"TSR_PCKG_NM\").distinct().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84e180f6-7dd2-4a18-8c81-c0d8c7267def",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dim Pkg"
    }
   },
   "outputs": [],
   "source": [
    "#schema\n",
    "schema_dim_pkg = StructType([\n",
    "    StructField(\"TSR_PCKG_NM\", StringType(), nullable=False),\n",
    "    StructField(\"PKG_CAT\", StringType(), True),\n",
    "    StructField(\"Pkg_Cat_Desc\", StringType(), True)\n",
    "])\n",
    "\n",
    "#agregando dado para criar dimensao\n",
    "dim_pkg = spark.table(\"ab_inbev.bronze.beverage_sales\").select(\"TSR_PCKG_NM\", \"PKG_CAT\", \"Pkg_Cat_Desc\").distinct()\n",
    "\n",
    "\n",
    "#forcando schema\n",
    "dim_pkg = spark.createDataFrame(dim_pkg.rdd, schema=schema_dim_pkg)\n",
    "\n",
    "#escrita\n",
    "dim_pkg.write.mode(\"overwrite\").saveAsTable(\"ab_inbev.silver.dim_pkg\")\n",
    "\n",
    "#chave primaria\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.dim_pkg ALTER COLUMN TSR_PCKG_NM SET NOT NULL\")\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.dim_pkg ADD PRIMARY KEY (TSR_PCKG_NM)\")\n",
    "\n",
    "spark.table(\"ab_inbev.silver.dim_pkg\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9005a301-a586-4003-ae7b-29cd6de2f713",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dim date"
    }
   },
   "outputs": [],
   "source": [
    "# schema\n",
    "schema_dim_date = StructType(\n",
    "    [\n",
    "        StructField(\"DATE\", DateType(), nullable=False),\n",
    "        StructField(\"YEAR\", IntegerType(), False),\n",
    "        StructField(\"MONTH\", IntegerType(), False),\n",
    "        StructField(\"PERIOD\", IntegerType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# agregando dado para criar dimensao\n",
    "dim_date = (\n",
    "    spark.table(\"ab_inbev.bronze.beverage_sales\")\n",
    "    .withColumn(\"DATE\", to_date(col(\"DATE\"), \"M/d/yyyy\"))\n",
    "    .withColumn(\"YEAR\", col(\"YEAR\").cast(\"int\"))\n",
    "    .withColumn(\"MONTH\", col(\"MONTH\").cast(\"int\"))\n",
    "    .withColumn(\"PERIOD\", col(\"PERIOD\").cast(\"int\"))\n",
    "    .select(\"DATE\", \"YEAR\", \"MONTH\", \"PERIOD\")\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "# forcando schema\n",
    "dim_date = spark.createDataFrame(dim_date.rdd, schema=schema_dim_date)\n",
    "\n",
    "# escrita\n",
    "dim_date.write.mode(\"overwrite\").saveAsTable(\"ab_inbev.silver.dim_date\")\n",
    "\n",
    "# chave primaria\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.dim_date ALTER COLUMN `DATE` SET NOT NULL\")\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.dim_date ADD PRIMARY KEY (`DATE`)\")\n",
    "\n",
    "spark.table(\"ab_inbev.silver.dim_date\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e073e94c-1678-440e-9902-aa470d1bd681",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Fatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65916e4a-6e0e-415b-b63b-3ae3f6e1562b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fato sale"
    }
   },
   "outputs": [],
   "source": [
    "schema_fato = StructType(\n",
    "    [\n",
    "        StructField(\"sale_id\", LongType(), nullable=False),\n",
    "        StructField(\"DATE\", DateType(), nullable=False),\n",
    "        StructField(\"CE_BRAND_FLVR\", StringType(), nullable=False),\n",
    "        StructField(\"TRADE_CHNL_DESC\", StringType(), nullable=False),\n",
    "        StructField(\"TSR_PCKG_NM\", StringType(), nullable=False),\n",
    "        StructField(\"Volume\", FloatType(), True),\n",
    "        StructField(\"Btlr_Org_LVL_C_Desc\", StringType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_fato = (\n",
    "    spark.table(\"ab_inbev.bronze.beverage_sales_and_channels\")\n",
    "    .withColumn(\"sale_id\", monotonically_increasing_id())\n",
    "    .withColumn(\"DATE\", to_date(col(\"DATE\"), \"M/d/yyyy\"))\n",
    "    .withColumn(\"Volume\", col(\"Volume\").cast(\"float\"))\n",
    "\n",
    "    .select(\n",
    "        \"sale_id\", \"DATE\", \"CE_BRAND_FLVR\", \"TRADE_CHNL_DESC\", \"TSR_PCKG_NM\", \"Volume\", \"Btlr_Org_LVL_C_Desc\"\n",
    "    )\n",
    ")\n",
    "\n",
    "df_fato = spark.createDataFrame(df_fato.rdd, schema=schema_fato)\n",
    "\n",
    "#escrita\n",
    "df_fato.write.mode(\"overwrite\").saveAsTable(\"ab_inbev.silver.fato_sales\")\n",
    "\n",
    "#chave primaria\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.fato_sales ALTER COLUMN sale_id SET NOT NULL\")\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.fato_sales ADD PRIMARY KEY (sale_id)\")\n",
    "\n",
    "#chaves estrangeiras\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.fato_sales ADD FOREIGN KEY (`DATE`) REFERENCES ab_inbev.silver.dim_date(`DATE`)\") \n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.fato_sales ADD FOREIGN KEY (CE_BRAND_FLVR) REFERENCES ab_inbev.silver.dim_brand(CE_BRAND_FLVR)\")\n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.fato_sales ADD FOREIGN KEY (TRADE_CHNL_DESC) REFERENCES ab_inbev.silver.dim_channels(TRADE_CHNL_DESC)\")  \n",
    "spark.sql(\"ALTER TABLE ab_inbev.silver.fato_sales ADD FOREIGN KEY (TSR_PCKG_NM) REFERENCES ab_inbev.silver.dim_pkg(TSR_PCKG_NM)\")\n",
    "\n",
    "spark.table(\"ab_inbev.silver.fato_sales\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7209390768902709,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
